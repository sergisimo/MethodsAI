{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json \n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printConvo(userData, systemData):\n",
    "    print(\"session id:\", userData[\"session-id\"])\n",
    "\n",
    "    print(userData[\"task-information\"][\"goal\"][\"text\"])\n",
    "\n",
    "    temp = 0\n",
    "    for speach in systemData[\"turns\"]:\n",
    "        print(\"system:\", speach[\"output\"][\"transcript\"])\n",
    "        print(\"user:\", userData[\"turns\"][temp][\"transcription\"])\n",
    "        temp += 1\n",
    "\n",
    "def writeFiles(userData, systemData, conversationsFile, utterancesFile):\n",
    "    \n",
    "    conversationsFile.write(\"session id: %s\\n\" % userData[\"session-id\"])\n",
    "    conversationsFile.write(\"%s\\n\" % userData[\"task-information\"][\"goal\"][\"text\"])\n",
    "\n",
    "    temp = 0\n",
    "    for speach in systemData[\"turns\"]:\n",
    "        \n",
    "        dialogAct = userData[\"turns\"][temp][\"semantics\"][\"cam\"]\n",
    "        utteranceContent = userData[\"turns\"][temp][\"transcription\"]\n",
    "        \n",
    "        conversationsFile.write(\"system: %s\\n\" %  speach[\"output\"][\"transcript\"])\n",
    "        conversationsFile.write(\"user: %s\\n\" % utteranceContent)\n",
    "        utterancesFile.write(\"%s %s\\n\" % (dialogAct.split(\"(\")[0], utteranceContent.lower()))\n",
    "        \n",
    "        temp += 1\n",
    "    \n",
    "    conversationsFile.write(\"\\n\\n\")\n",
    "\n",
    "def writeFile(waiting):\n",
    "    if waiting is False:\n",
    "        conversationsFile = open(\"convo.txt\", \"w+\")\n",
    "        utterancesFile = open(\"utterances.txt\", \"w+\")\n",
    "    \n",
    "    userFiles = glob.glob('**/label.json', recursive=True)\n",
    "    systemFiles = glob.glob('**/log.json', recursive=True)\n",
    "    i = 0\n",
    "    for userFile in userFiles:\n",
    "        with open(userFile) as f:\n",
    "            userData = json.load(f)\n",
    "        with open(systemFiles[i]) as f:\n",
    "            systemData = json.load(f)\n",
    "        i += 1\n",
    "        if waiting is True :\n",
    "            printConvo(userData, systemData)\n",
    "            input('press Enter to display another chat both conversation')\n",
    "        else: \n",
    "            writeFiles(userData, systemData, conversationsFile, utterancesFile)\n",
    "\n",
    "    if waiting is False: \n",
    "        conversationsFile.close()\n",
    "        utterancesFile.close()\n",
    "\n",
    "writeFile(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSets():\n",
    "    utterancesFile = open(\"utterances.txt\", \"r\")\n",
    "    utterancesData = {}\n",
    "    for line in utterancesFile:\n",
    "        line = line.split(\" \", 1)\n",
    "        if line[0] not in utterancesData:\n",
    "            utterancesData[line[0]] = []    \n",
    "        utterancesData[line[0]].append(line[1].strip())\n",
    "\n",
    "    trainingData = {}\n",
    "    testData = {}\n",
    "    for dialogType in utterancesData:\n",
    "        splitted = np.split(utterancesData[dialogType], [int(len(utterancesData[dialogType]) * 0.85)])\n",
    "        trainingData[dialogType] = splitted[0].tolist()\n",
    "        testData[dialogType] = splitted[1].tolist()\n",
    "    \n",
    "    utterancesFile.close()\n",
    "        \n",
    "    return trainingData, testData\n",
    "\n",
    "createDataSets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruleBasedClassifier(sentence):\n",
    "    \n",
    "    keywords = {\"affirm\":[\"yes\", \"yeah\", \"yea\"],\n",
    "                \"confirm\":[\"is it\", \"does it\"],\n",
    "                \"bye\": [\"bye\"],\n",
    "                \"deny\":[\"no\", \"do not\", \"dont\"],\n",
    "                \"hello\":[\"hi\", \"hello\"],\n",
    "                \"inform\":[\"any\", \"dont care\", \"do not care\", \"doesnt matter\", \"does not matter\",\"south\",\n",
    "                \"north\",\"east\",\"west\",\"centre\", \"center\", \"expensive\", \"moderately\",\"moderate\",\"cheap\",\n",
    "                \"creative\", \"christmas\",\"halal\", \"vegetarian\",\"indian\",\"cantonese\",\"american\",\"persian\",\n",
    "                \"european\",\"chinese\",\"sea food\",\"spanish\",\"portuguese\",\"italian\",\"mediterranean\",\"gastropub\",\n",
    "                \"steak\",\"bistro\",\"british\",\"japanese\",\"danish\",\"lebanese\",\"caribbean\",\"thai\",\"asian\",\"welsh\",\n",
    "                \"french\",\"australian\",\"brazilian\",\"irish\",\"english\",\"polynesian\",\"corsica\",\"vietnamese\",\"turkish\",\n",
    "                \"mexican\",\"moroccan\"],\n",
    "                \"negate\":[\"no\"],\n",
    "                \"repeat\":[\"repeat\"],\n",
    "                \"requalts\": [\"what about\",\"how about\",\"else\",\"anything\",\"different\"],\n",
    "                \"reqmore\":[\"more\"],\n",
    "                \"request\":[\"address\",\"area\",\"location\",\"type\", \"type of food\",\"price\",\"phone\",\"phonenumber\",\"telephone\",\"post code\", \"postcode\"],\n",
    "                \"restart\":[\"start over\", \"restart\"],\n",
    "                \"ack\" : [\"okay\"],\n",
    "                \"thankyou\":[\"thank you\", \"thanks\"],\n",
    "                \"null\": [\"noise\", \"unintelligible\"]}\n",
    "\n",
    "    #Loops through the categories and checks whether a the keyword is in the sentence\n",
    "    for category in keywords:\n",
    "        for keyword in keywords[category]:\n",
    "            if keyword in sentence:\n",
    "                return category\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Base Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRuleBasedClassifier(testData):\n",
    "\n",
    "    total = 0\n",
    "    amountRight = 0\n",
    "    for actCategory in testData:\n",
    "        total += len(testData[actCategory])\n",
    "        for sentence in testData[actCategory]:\n",
    "            category = ruleBasedClassifier(sentence)\n",
    "            if category == actCategory:\n",
    "                amountRight += 1\n",
    "                \n",
    "    proportion = (amountRight / total) * 100\n",
    "    print(\"Accuracy = \", proportion, \"%\")\n",
    "\n",
    "def manualRuleBasedClassifier():\n",
    "    \n",
    "    while True:\n",
    "        print(\"Write the next sentence: \")\n",
    "        sentence = input()\n",
    "        if (sentence == 'exit'):\n",
    "            break\n",
    "        print(\"The category of your sentence is: \", ruleBasedClassifier(sentence))\n",
    "        \n",
    "    \n",
    "trainingData, testData = createDataSets()\n",
    "testRuleBasedClassifier(testData)\n",
    "manualRuleBasedClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportional Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProportions(trainingData):\n",
    "    \n",
    "    total = 0\n",
    "    proportions = {}\n",
    "    \n",
    "    for actCategory in trainingData:\n",
    "        total += len(trainingData[actCategory])\n",
    "    \n",
    "    for actCategory in trainingData:\n",
    "        proportions[actCategory] = len(trainingData[actCategory]) * 100 / total\n",
    "    \n",
    "    return proportions\n",
    "    \n",
    "\n",
    "def proportionalBasedClassifier(proportions):\n",
    "    return random.choices(list(proportions.keys()), list(proportions.values()))\n",
    "    \n",
    "trainingData, testData = createDataSets()\n",
    "proportions = calculateProportions(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportional Based Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testProportionalBasedClassifier(testData, proportions):\n",
    "\n",
    "    total = 0\n",
    "    amountRight = 0\n",
    "    for actCategory in testData:\n",
    "        total += len(testData[actCategory])\n",
    "        for sentence in testData[actCategory]:\n",
    "            category = proportionalBasedClassifier(proportions)\n",
    "            if category[0] == actCategory:\n",
    "                amountRight += 1\n",
    "                \n",
    "    proportion = (amountRight / total) * 100\n",
    "    print(\"Accuracy = \", proportion, \"%\")\n",
    "\n",
    "def manualProportionalBasedClassifier(proportions):\n",
    "    \n",
    "    while True:\n",
    "        print(\"Write the next sentence: \")\n",
    "        sentence = input()\n",
    "        if (sentence == 'exit'):\n",
    "            break\n",
    "        print(\"The category of your sentence is: \", proportionalBasedClassifier(proportions)[0])\n",
    "        \n",
    "trainingData, testData = createDataSets()\n",
    "proportions = calculateProportions(trainingData)\n",
    "testProportionalBasedClassifier(testData, proportions)\n",
    "manualProportionalBasedClassifier(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def tokenizeSentence(vocab, sentence):\n",
    "    words = word_extraction(sentence)\n",
    "    bag_vector = numpy.zeros(len(vocab))\n",
    "    for w in words:\n",
    "        for i,word in enumerate(vocab):\n",
    "            if word == w:\n",
    "                bag_vector[i] += 1\n",
    "    \n",
    "    return bag_vector\n",
    "\n",
    "def manualMLClassifier(classifier, vocab):\n",
    "    \n",
    "    while True:\n",
    "        print(\"Write the next sentence: \")\n",
    "        sentence = input()\n",
    "        if (sentence == 'exit'):\n",
    "            break\n",
    "        vector = tokenizeSentence(vocab, sentence)\n",
    "        print(\"The category of your sentence is: \", classifier.predict(vector))\n",
    "'''\n",
    "\n",
    "def tokenizeData(trainingData, testData):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    for dialogType in trainingData:        \n",
    "        for sentence in trainingData[dialogType]:\n",
    "            X.append(sentence)\n",
    "            Y.append(dialogType)\n",
    "            \n",
    "    for dialogType in testData:        \n",
    "        for sentence in testData[dialogType]:\n",
    "            X.append(sentence)\n",
    "            Y.append(dialogType)\n",
    "            \n",
    "    X = vectorizer.fit_transform(X)\n",
    "    \n",
    "    return X.toarray(), Y,\n",
    "\n",
    "trainingData, testData = createDataSets()\n",
    "X, Y = tokenizeData(trainingData, testData)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Accuracy: \", clf.score(X_test, Y_test) * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
