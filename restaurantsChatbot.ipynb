{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json \n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printConvo(userData, systemData):\n",
    "    \"\"\"\n",
    "    This function takes the tow files input userData and systemData\n",
    "    And prints conversation in turns in the terminal \n",
    "    With the for loop for the user and the system to take turns \n",
    "    and print the coherent conversation \n",
    "    \"\"\"\n",
    "    print(\"session id:\", userData[\"session-id\"])\n",
    "\n",
    "    print(userData[\"task-information\"][\"goal\"][\"text\"])\n",
    "\n",
    "    temp = 0\n",
    "    for speach in systemData[\"turns\"]:\n",
    "        print(\"system:\", speach[\"output\"][\"transcript\"])\n",
    "        print(\"user:\", userData[\"turns\"][temp][\"transcription\"])\n",
    "        temp += 1\n",
    "\n",
    "def writeFiles(userData, systemData, conversationsFile, utterancesFile):\n",
    "    \"\"\"\n",
    "    writeFiles function takes the input data and creates new txt file with all the conversations between \n",
    "    the bot and user that has occurred\n",
    "    Using the for loop in order to maintain the natural occurrences  of the conversation\n",
    "    \n",
    "    \"\"\"\n",
    "    conversationsFile.write(\"session id: %s\\n\" % userData[\"session-id\"])\n",
    "    conversationsFile.write(\"%s\\n\" % userData[\"task-information\"][\"goal\"][\"text\"])\n",
    "\n",
    "    temp = 0\n",
    "    for speach in systemData[\"turns\"]:\n",
    "        \n",
    "        dialogAct = userData[\"turns\"][temp][\"semantics\"][\"cam\"]\n",
    "        utteranceContent = userData[\"turns\"][temp][\"transcription\"]\n",
    "        \n",
    "        conversationsFile.write(\"system: %s\\n\" %  speach[\"output\"][\"transcript\"])\n",
    "        conversationsFile.write(\"user: %s\\n\" % utteranceContent)\n",
    "        utterancesFile.write(\"%s %s\\n\" % (dialogAct.split(\"(\")[0], utteranceContent.lower()))\n",
    "        \n",
    "        temp += 1\n",
    "    \n",
    "    conversationsFile.write(\"\\n\\n\")\n",
    "\n",
    "def writeFile(waiting):\n",
    "    \"\"\"\n",
    "    This function takes the Boolean values as an input\n",
    "    and opens the json files\n",
    "    If the input is False firstly it opens the files to scribe conversations  into \n",
    "    if input is True the function calls printConvo function and the conversation is being displayed in the \n",
    "    terminal\n",
    "    \n",
    "    \"\"\"\n",
    "    if waiting is False:\n",
    "        conversationsFile = open(\"convo.txt\", \"w+\")\n",
    "        utterancesFile = open(\"utterances.txt\", \"w+\")\n",
    "    \n",
    "    userFiles = glob.glob('**/label.json', recursive=True)\n",
    "    systemFiles = glob.glob('**/log.json', recursive=True)\n",
    "    i = 0\n",
    "    for userFile in userFiles:\n",
    "        with open(userFile) as f:\n",
    "            userData = json.load(f)\n",
    "        with open(systemFiles[i]) as f:\n",
    "            systemData = json.load(f)\n",
    "        i += 1\n",
    "        if waiting is True :\n",
    "            printConvo(userData, systemData)\n",
    "            input('press Enter to display another chat both conversation')\n",
    "        else: \n",
    "            writeFiles(userData, systemData, conversationsFile, utterancesFile)\n",
    "\n",
    "    if waiting is False: \n",
    "        conversationsFile.close()\n",
    "        utterancesFile.close()\n",
    "\n",
    "writeFile(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSets():\n",
    "    \"\"\"\n",
    "    createDataSets function opens the file with the conversations  \n",
    "    iterates though the conversations creating the data sets and splitting  85-15 for the training and test sets\n",
    "    \n",
    "    returns dictionaries training set and test set\n",
    "    \"\"\"\n",
    "    utterancesFile = open(\"utterances.txt\", \"r\")\n",
    "    utterancesData = {}\n",
    "    for line in utterancesFile:\n",
    "        line = line.split(\" \", 1)\n",
    "        if line[0] not in utterancesData:\n",
    "            utterancesData[line[0]] = []    \n",
    "        utterancesData[line[0]].append(line[1].strip())\n",
    "\n",
    "    trainingData = {}\n",
    "    testData = {}\n",
    "    for dialogType in utterancesData:\n",
    "        splitted = np.split(utterancesData[dialogType], [int(len(utterancesData[dialogType]) * 0.85)])\n",
    "        trainingData[dialogType] = splitted[0].tolist()\n",
    "        testData[dialogType] = splitted[1].tolist()\n",
    "    \n",
    "    utterancesFile.close()\n",
    "        \n",
    "    return trainingData, testData\n",
    "\n",
    "createDataSets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ruleBasedClassifier(sentence):\n",
    "    \"\"\"\n",
    "    This function takes the sentence and classify it accordingly to the created keywords\n",
    "    Loops through the categories and checks whether the keyword is in the sentence\n",
    "    Return None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    keywords = {\"affirm\":[\"yes\", \"yeah\", \"yea\"],\n",
    "                \"confirm\":[\"is it\", \"does it\"],\n",
    "                \"bye\": [\"bye\"],\n",
    "                \"deny\":[\"no\", \"do not\", \"dont\"],\n",
    "                \"hello\":[\"hi\", \"hello\"],\n",
    "                \"inform\":[\"any\", \"dont care\", \"do not care\", \"doesnt matter\", \"does not matter\",\"south\",\n",
    "                \"north\",\"east\",\"west\",\"centre\", \"center\", \"expensive\", \"moderately\",\"moderate\",\"cheap\",\n",
    "                \"creative\", \"christmas\",\"halal\", \"vegetarian\",\"indian\",\"cantonese\",\"american\",\"persian\",\n",
    "                \"european\",\"chinese\",\"sea food\",\"spanish\",\"portuguese\",\"italian\",\"mediterranean\",\"gastropub\",\n",
    "                \"steak\",\"bistro\",\"british\",\"japanese\",\"danish\",\"lebanese\",\"caribbean\",\"thai\",\"asian\",\"welsh\",\n",
    "                \"french\",\"australian\",\"brazilian\",\"irish\",\"english\",\"polynesian\",\"corsica\",\"vietnamese\",\"turkish\",\n",
    "                \"mexican\",\"moroccan\"],\n",
    "                \"negate\":[\"no\"],\n",
    "                \"repeat\":[\"repeat\"],\n",
    "                \"requalts\": [\"what about\",\"how about\",\"else\",\"anything\",\"different\"],\n",
    "                \"reqmore\":[\"more\"],\n",
    "                \"request\":[\"address\",\"area\",\"location\",\"type\", \"type of food\",\"price\",\"phone\",\"phonenumber\",\"telephone\",\"post code\", \"postcode\"],\n",
    "                \"restart\":[\"start over\", \"restart\"],\n",
    "                \"ack\" : [\"okay\"],\n",
    "                \"thankyou\":[\"thank you\", \"thanks\"],\n",
    "                \"null\": [\"noise\", \"unintelligible\"]}\n",
    "\n",
    "    #Loops through the categories and checks whether a the keyword is in the sentence\n",
    "    for category in keywords:\n",
    "        for keyword in keywords[category]:\n",
    "            if keyword in sentence:\n",
    "                return category\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Base Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createDataSets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1f5b01d2aaa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateDataSets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mtestRuleBasedClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mmanualRuleBasedClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'createDataSets' is not defined"
     ]
    }
   ],
   "source": [
    "def testRuleBasedClassifier(testData):\n",
    "    \"\"\"\n",
    "    Iterates though the input data, calls the function ruleBasedClassifier for each of the sentences and checks\n",
    "    if it was classified correctly\n",
    "    Takes the correctly classified points and divides it with the total amount of points and prints the \n",
    "    percentage  of correctly classified points with ruleBasedClassifier\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    total = 0\n",
    "    amountRight = 0\n",
    "    for actCategory in testData:\n",
    "        total += len(testData[actCategory])\n",
    "        for sentence in testData[actCategory]:\n",
    "            category = ruleBasedClassifier(sentence)\n",
    "            if category == actCategory:\n",
    "                amountRight += 1\n",
    "                \n",
    "    proportion = (amountRight / total) * 100\n",
    "    print(\"Accuracy = \", proportion, \"%\")\n",
    "\n",
    "def manualRuleBasedClassifier():\n",
    "    \"\"\"\n",
    "    allows the user to input the sentence and with function ruleBasedClassifier \n",
    "    classify user input and prints the result of the classification \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        print(\"Write the next sentence: \")\n",
    "        sentence = input()\n",
    "        if (sentence == 'exit'):\n",
    "            break\n",
    "        print(\"The category of your sentence is: \", ruleBasedClassifier(sentence))\n",
    "        \n",
    "    \n",
    "trainingData, testData = createDataSets()\n",
    "testRuleBasedClassifier(testData)\n",
    "manualRuleBasedClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportional Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateProportions(trainingData):\n",
    "    \"\"\"\n",
    "    Calculates the proportion of the data regarding its categories \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    proportions = {}\n",
    "    \n",
    "    for actCategory in trainingData:\n",
    "        total += len(trainingData[actCategory])\n",
    "    \n",
    "    for actCategory in trainingData:\n",
    "        proportions[actCategory] = len(trainingData[actCategory]) * 100 / total\n",
    "    \n",
    "    return proportions\n",
    "    \n",
    "\n",
    "def proportionalBasedClassifier(proportions):\n",
    "    return random.choices(list(proportions.keys()), list(proportions.values()))\n",
    "    \n",
    "trainingData, testData = createDataSets()\n",
    "proportions = calculateProportions(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportional Based Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createDataSets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-644db70eebf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The category of your sentence is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproportionalBasedClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproportions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtrainingData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateDataSets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mproportions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculateProportions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtestProportionalBasedClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproportions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'createDataSets' is not defined"
     ]
    }
   ],
   "source": [
    "def testProportionalBasedClassifier(testData, proportions):\n",
    "    \"\"\"\n",
    "    The function takes as in input the data and the calculated proportions \n",
    "    Loops though the data and classify each sentence with the proportionalBasedClassifier\n",
    "    prints the accuracy percentage of correctly classified sentences\n",
    "    \"\"\"\n",
    "\n",
    "    total = 0\n",
    "    amountRight = 0\n",
    "    for actCategory in testData:\n",
    "        total += len(testData[actCategory])\n",
    "        for sentence in testData[actCategory]:\n",
    "            category = proportionalBasedClassifier(proportions)\n",
    "            if category[0] == actCategory:\n",
    "                amountRight += 1\n",
    "                \n",
    "    proportion = (amountRight / total) * 100\n",
    "    print(\"Accuracy = \", proportion, \"%\")\n",
    "\n",
    "def manualProportionalBasedClassifier(proportions):\n",
    "    \"\"\"\n",
    "    Takes the input of the user and using the proportionalBasedClassifier classifies  the input\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        print(\"Write the next sentence: \")\n",
    "        sentence = input()\n",
    "        if (sentence == 'exit'):\n",
    "            break\n",
    "        print(\"The category of your sentence is: \", proportionalBasedClassifier(proportions)[0])\n",
    "        \n",
    "trainingData, testData = createDataSets()\n",
    "proportions = calculateProportions(trainingData)\n",
    "testProportionalBasedClassifier(testData, proportions)\n",
    "manualProportionalBasedClassifier(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def tokenizeSentence(vocab, sentence):\n",
    "    words = word_extraction(sentence)\n",
    "    bag_vector = numpy.zeros(len(vocab))\n",
    "    for w in words:\n",
    "        for i,word in enumerate(vocab):\n",
    "            if word == w:\n",
    "                bag_vector[i] += 1\n",
    "    \n",
    "    return bag_vector\n",
    "\n",
    "def manualMLClassifier(classifier, vocab):\n",
    "    \n",
    "    while True:\n",
    "        print(\"Write the next sentence: \")\n",
    "        sentence = input()\n",
    "        if (sentence == 'exit'):\n",
    "            break\n",
    "        vector = tokenizeSentence(vocab, sentence)\n",
    "        print(\"The category of your sentence is: \", classifier.predict(vector))\n",
    "'''\n",
    "\n",
    "def tokenizeData(trainingData, testData):\n",
    "    \"\"\"\n",
    "    This function takes the input of the training and test data \n",
    "    For both it iterates  though the data separating  the sentences and its type\n",
    "    Transform  the array of sentences into bag of words representation \n",
    "    \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    for dialogType in trainingData:        \n",
    "        for sentence in trainingData[dialogType]:\n",
    "            X.append(sentence)\n",
    "            Y.append(dialogType)\n",
    "            \n",
    "    for dialogType in testData:        \n",
    "        for sentence in testData[dialogType]:\n",
    "            X.append(sentence)\n",
    "            Y.append(dialogType)\n",
    "            \n",
    "    X = vectorizer.fit_transform(X)\n",
    "    \n",
    "    return X.toarray(), Y,\n",
    "\n",
    "trainingData, testData = createDataSets()\n",
    "X, Y = tokenizeData(trainingData, testData)\n",
    "#Splits the data for the train and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "# Creates the Decision tree classifier  \n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "# fits the data into the created model \n",
    "clf = clf.fit(X_train, Y_train)\n",
    "# prints the accuracy of the classifier \n",
    "print(\"Accuracy: \", clf.score(X_test, Y_test) * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
